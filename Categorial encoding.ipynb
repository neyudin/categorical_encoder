{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T18:08:00.361853",
     "start_time": "2017-08-28T18:08:00.072396"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T18:08:00.733415",
     "start_time": "2017-08-28T18:08:00.604219"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class TargetEncoder:\n",
    "    \n",
    "    \n",
    "    def __init__(self, alpha=1.0, priors=None, n_folds=3, random_state=317):\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        \n",
    "        self._alpha = alpha\n",
    "        \n",
    "        if priors is not None:\n",
    "            self._priors = priors.copy()\n",
    "        else:\n",
    "            self._priors = None\n",
    "        \n",
    "        self._kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, X, y, features_values_list):\n",
    "        import numpy as np\n",
    "        from sklearn.preprocessing import LabelEncoder as LE\n",
    "        from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "        \n",
    "        self._ohe = OHE(n_values=np.array([np.array(arr).shape[0] for arr in features_values_list]),\n",
    "                        dtype=np.int32, sparse=True)\n",
    "        self._le_list = []\n",
    "        X_ohe = np.zeros(X.shape).astype(np.int32)\n",
    "        for i in range(X_ohe.shape[1]):\n",
    "            self._le_list.append(LE())\n",
    "            self._le_list[i].fit(features_values_list[i])\n",
    "            X_ohe[:, i] = self._le_list[i].transform(X[:, i])\n",
    "        X_ohe = self._ohe.fit_transform(X_ohe)\n",
    "        y_tmp = LE().fit_transform(y)\n",
    "        self._y_unique = np.unique(y_tmp)\n",
    "\n",
    "        X_res = np.zeros((X.shape[0], (2 * self._y_unique.shape[0] + 1) * X.shape[1]))\n",
    "\n",
    "        self._global_counts_array = np.zeros(self._ohe.feature_indices_[-1]).astype(np.int32)\n",
    "        self._global_successes_matrix = np.zeros((self._y_unique.shape[0],\\\n",
    "                                                  self._ohe.feature_indices_[-1])).astype(np.int32)\n",
    "        \n",
    "        if self._priors is None:\n",
    "            self._priors = np.zeros(self._y_unique.shape[0])\n",
    "            for class_id in self._y_unique:\n",
    "                self._priors[class_id] = (y_tmp == class_id).sum() / y_tmp.shape[0]\n",
    "\n",
    "        for train_idxs, test_idxs in self._kfold.split(X, y_tmp):\n",
    "            counts_array = np.array(X_ohe[train_idxs].sum(axis=0))[0].astype(np.int32)\n",
    "    \n",
    "            successes_matrix = np.zeros((self._y_unique.shape[0], self._ohe.feature_indices_[-1])).astype(np.int32)\n",
    "            for class_id in self._y_unique:\n",
    "                successes_matrix[class_id] = np.array(X_ohe[train_idxs[y_tmp[train_idxs] ==\\\n",
    "                                                               class_id]].sum(axis=0))[0].astype(np.int32)\n",
    "    \n",
    "            self._global_counts_array += counts_array\n",
    "            self._global_successes_matrix += successes_matrix\n",
    "    \n",
    "            for test_idx in test_idxs:\n",
    "                features_mask = X_ohe[test_idx].toarray()[0].astype(np.bool)\n",
    "        \n",
    "                X_res[test_idx, :X.shape[1]] = X.shape[0] / train_idxs.shape[0] * counts_array[features_mask]\n",
    "        \n",
    "                for class_id in self._y_unique:\n",
    "                    X_res[test_idx, (class_id + 1) * X.shape[1]: (class_id + 2) * X.shape[1]] =\\\n",
    "                    X.shape[0] / train_idxs.shape[0] * successes_matrix[class_id, features_mask]\n",
    "        \n",
    "                for class_id in self._y_unique:\n",
    "                    X_res[test_idx, (self._y_unique.shape[0] + class_id + 1) * X.shape[1]:\\\n",
    "                          (self._y_unique.shape[0] + class_id + 2) * X.shape[1]] =\\\n",
    "                          (X.shape[0] / train_idxs.shape[0] * successes_matrix[class_id,\\\n",
    "                           features_mask] + self._alpha * self._priors[class_id]) /\\\n",
    "                           (X.shape[0] / train_idxs.shape[0] * counts_array[features_mask] + self._alpha)\n",
    "                    \n",
    "        return X_res\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        import numpy as np\n",
    "        \n",
    "        X_ohe = np.zeros(X.shape).astype(np.int32)\n",
    "        for i in range(X.shape[1]):\n",
    "            X_ohe[:, i] = self._le_list[i].transform(X[:, i])\n",
    "        X_ohe = self._ohe.transform(X_ohe)\n",
    "        X_res = np.zeros((X.shape[0], (2 * self._y_unique.shape[0] + 1) * X.shape[1]))\n",
    "        \n",
    "        for idx in range(X.shape[0]):\n",
    "            features_mask = X_ohe[idx].toarray()[0].astype(np.bool)\n",
    "            \n",
    "            X_res[idx, :X.shape[1]] = self._global_counts_array[features_mask]\n",
    "            \n",
    "            for class_id in self._y_unique:\n",
    "                X_res[idx, (class_id + 1) * X.shape[1]: (class_id + 2) * X.shape[1]] =\\\n",
    "                      self._global_successes_matrix[class_id, features_mask]\n",
    "                \n",
    "            for class_id in self._y_unique:\n",
    "                X_res[idx, (self._y_unique.shape[0] + class_id + 1) * X.shape[1]:\\\n",
    "                           (self._y_unique.shape[0] + class_id + 2) * X.shape[1]] =\\\n",
    "                      (self._global_successes_matrix[class_id, features_mask] +\\\n",
    "                       self._alpha * self._priors[class_id]) /\\\n",
    "                      (self._global_counts_array[features_mask] + self._alpha)\n",
    "        \n",
    "        return X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T18:08:01.171855",
     "start_time": "2017-08-28T18:08:01.148356"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class TargetEncoderCV:\n",
    "    \n",
    "    \n",
    "    def __init__(self, scorer, cv_n_folds=3, cv_random_state=317, alpha=1.0, priors=None, n_folds=3,\\\n",
    "                 random_state=317):\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        \n",
    "        self._scorer = scorer\n",
    "        self._cv_kfold = StratifiedKFold(n_splits=cv_n_folds, shuffle=True, random_state=cv_random_state)\n",
    "        \n",
    "        self._te = TargetEncoder(alpha=alpha, priors=priors, n_folds=n_folds, random_state=random_state)\n",
    "    \n",
    "    \n",
    "    def cv_routine_smooth(self, clf, X, y, features_values_list, clf_params):\n",
    "        import numpy as np\n",
    "        \n",
    "        clf.set_params(**clf_params)\n",
    "        \n",
    "        cv_res = []\n",
    "        \n",
    "        for train_idxs, test_idxs in self._cv_kfold.split(X, y):\n",
    "            X_train = self._te.fit_transform(X[train_idxs], y[train_idxs], features_values_list)\n",
    "            X_test = self._te.transform(X[test_idxs])\n",
    "            \n",
    "            clf.fit(X_train, y[train_idxs])\n",
    "            \n",
    "            cv_res.append(self._scorer(y_true=y[test_idxs], y_score=clf.predict_proba(X_test)[:, 1]))\n",
    "        \n",
    "        return np.mean(cv_res), np.std(cv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T18:08:01.816737",
     "start_time": "2017-08-28T18:08:01.766288"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('amazon.csv', dtype={'ACTION': np.int64,\n",
    "                                        'RESOURCE': str,\n",
    "                                        'MGR_ID': str,\n",
    "                                        'ROLE_ROLLUP_1': str,\n",
    "                                        'ROLE_ROLLUP_2': str,\n",
    "                                        'ROLE_DEPTNAME': str,\n",
    "                                        'ROLE_TITLE': str,\n",
    "                                        'ROLE_FAMILY_DESC': str,\n",
    "                                        'ROLE_FAMILY': str,\n",
    "                                        'ROLE_CODE': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T18:08:02.512016",
     "start_time": "2017-08-28T18:08:02.331081"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "col_names = data.columns\n",
    "for i in range(1, col_names.shape[0]):\n",
    "    for j in range(i + 1, col_names.shape[0]):\n",
    "        data[col_names[i] + '.' + col_names[j]] = data[col_names[i]] + '.' + data[col_names[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T18:09:53.452830",
     "start_time": "2017-08-28T18:08:02.880477"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACTION    0.94211\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T18:09:53.458079",
     "start_time": "2017-08-28T18:09:53.454529"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 46)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T18:09:54.519340",
     "start_time": "2017-08-28T18:09:53.459414"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "features_values_list = []\n",
    "for i in range(1, data.shape[1]):\n",
    "    features_values_list.append(np.unique(data.iloc[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T18:14:32.209416",
     "start_time": "2017-08-28T18:09:54.521460"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.86686758472026215, 0.0050686411353453352)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "te_cv = TargetEncoderCV(scorer=roc_auc_score, alpha=0.001, n_folds=2)\n",
    "te_cv.cv_routine_smooth(RFC(n_estimators=200), data.iloc[:, 1:].as_matrix(), data.iloc[:, 0].as_matrix(),\n",
    "                        features_values_list, {'n_estimators': 200, 'n_jobs': 4, 'random_state': 317})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
